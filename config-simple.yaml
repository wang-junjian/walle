# Continue.dev Configuration for Walle AI Assistant
# å–ä»£ .env.local æ–‡ä»¶çš„é…ç½®æ–¹æ¡ˆ
# å‚è€ƒï¼šhttps://docs.continue.dev/reference

# ğŸ¤– ä¸»è¦æ¨¡å‹é…ç½®
models:
  # æ™ºè°±AI - ä¸»èŠå¤©æ¨¡å‹ï¼ˆæ¥è‡ª .env.localï¼‰
  - name: "GLM-4.5-Flash"
    provider: "openai" 
    model: "GLM-4.5-Flash"
    apiKey: ""
    apiBase: "https://open.bigmodel.cn/api/paas/v4/"
    contextLength: 128000
    maxTokens: 8192
    temperature: 0.7
    roles: ["chat"]

  # æ™ºè°±AI - å¤‡ç”¨æ¨¡å‹ï¼ˆæ¥è‡ª MODEL_LISTï¼‰
  - name: "GLM-4-Flash"
    provider: "openai"
    model: "GLM-4-Flash-250414" 
    apiKey: ""
    apiBase: "https://open.bigmodel.cn/api/paas/v4/"
    contextLength: 128000
    maxTokens: 8192
    temperature: 0.7

  - name: "GLM-Z1-Flash"
    provider: "openai"
    model: "GLM-Z1-Flash"
    apiKey: "" 
    apiBase: "https://open.bigmodel.cn/api/paas/v4/"
    contextLength: 128000
    maxTokens: 8192
    temperature: 0.7

# ğŸ™ï¸ è¯­éŸ³è¯†åˆ«é…ç½®ï¼ˆæ¥è‡ª ASR_MODELï¼‰
speechToTextProvider:
  name: "SenseVoice Small"
  provider: "openai"
  model: "FunAudioLLM/SenseVoiceSmall"
  apiKey: ""
  apiBase: "https://open.bigmodel.cn/api/paas/v4/"

# ğŸ”Š è¯­éŸ³åˆæˆé…ç½®ï¼ˆæ¥è‡ª NEXT_PUBLIC_TTS_MODELï¼‰  
textToSpeechProvider:
  name: "CosyVoice2-0.5B"
  provider: "openai"
  model: "FunAudioLLM/CosyVoice2-0.5B"
  apiKey: ""
  apiBase: "https://open.bigmodel.cn/api/paas/v4/"
  voice: "anna"

# ğŸ“ åº”ç”¨é…ç½®ï¼ˆæ¥è‡ª NEXT_PUBLIC_APP_NAME å’Œ NEXT_PUBLIC_APP_VERSIONï¼‰
app:
  name: "Walle"
  version: "1.0.0"

# ğŸ” ä¸Šä¸‹æ–‡æä¾›è€…ï¼ˆåŸºç¡€é…ç½®ï¼‰
contextProviders:
  - name: "codebase"
  - name: "file" 
  - name: "open"
  - name: "terminal"

# âš¡ åŸºç¡€æ–œæ å‘½ä»¤
slashCommands:
  - name: "edit"
    description: "ç¼–è¾‘é€‰ä¸­çš„ä»£ç "
  - name: "comment" 
    description: "æ·»åŠ ä»£ç æ³¨é‡Š"
  - name: "cmd"
    description: "ç”Ÿæˆå‘½ä»¤è¡ŒæŒ‡ä»¤"

# ğŸ”§ ç³»ç»Ÿé…ç½®
system:
  timeout: 30000
  maxRetries: 3

# ğŸ¨ ç•Œé¢é…ç½®
ui:
  language: "zh"
  theme: "auto"

# ğŸ“Š é¥æµ‹è®¾ç½®
telemetry:
  enabled: false
